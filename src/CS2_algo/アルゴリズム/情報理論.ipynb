{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情報理論入門\n",
    "\n",
    "## ビット(bit)\n",
    "\n",
    "- 0,1 の列で表される\n",
    "- ビット数は情報量の単位としての芋を持つ\n",
    "  - ex. 5bit の情報 -> $2^{5}$=32 通りの情報\n",
    "- **1 バイト(B)=8[bit]**\n",
    "\n",
    "  ### 単位\n",
    "\n",
    "  - T(Tera) = $10^{12}$\n",
    "  - G(Giga) = $10^{9}$\n",
    "  - M(Mega) = $10^{6}$\n",
    "  - K(Kilo) = $10^{3}$\n",
    "  - c(centi) = $10^{-2}$\n",
    "  - m(milli) = $10^{-3}$\n",
    "  - μ(micro) = $10^{-6}$\n",
    "  - n(nano) = $10^{-9}$\n",
    "  - p(pico) = $10^{-12}$\n",
    "\n",
    "- 情報量は加法性が成り立つ\n",
    "\n",
    "## 情報量の定義\n",
    "\n",
    "確率 p で発生する事象の情報量 I\n",
    "$$I = -\\log_2 p \\;\\text{[bit]}$$\n",
    "\n",
    "ex. A さんのクラスがクラス 2 の時の事象の情報量(クラスは 20 あるとする)\n",
    "$$I = -\\log_2 \\frac{1}{20} \\approx 4.3219 \\;\\text{[bit]}$$\n",
    "\n",
    "- bit と同様加法性がある\n",
    "\n",
    "## 符号化\n",
    "\n",
    "情報をデジタル情報としてビット列(0,1)にする処理のこと\n",
    "\n",
    "## 情報エントロピー\n",
    "\n",
    "情報をできる限り少ないビット数で表現したい\n",
    "-> 情報量の平均のようなものが欲しい\n",
    "↑ のために情報エントロピーの概念を導入\n",
    "\n",
    "## 情報エントロピーの定義\n",
    "\n",
    "情報エントロピー H は情報量の期待値として定義される\n",
    "$$H = E[I] = -\\sum_{i=1}^n p_i \\log_2 p_i \\;\\text{[bit]}$$\n",
    "\n",
    "- 情報エントロピーの数が大きいほど 1bit あたりより多くの情報を表現できている\n",
    "- 0,1 の確率が均等になっている場合、情報エントロピーは最大値をとる(1bit が max)\n",
    "\n",
    "## 冗長化の定義\n",
    "\n",
    "最大エントロピー Hmax と実際のエントロピー H の相対的な差を表現する指数\n",
    "$$R = 1 - \\frac{H}{H_{\\text{max}}}$$\n",
    "\n",
    "- 1 に近い程冗長、0 に近いほど無駄がない\n",
    "\n",
    "### パリティビット\n",
    "\n",
    "- 元のビット列に冗長なビットを追加\n",
    "- パリティビットでは元のビット列に含まれる 1 の個数が偶数か奇数で 0,1 を表現する\n",
    "- 1 ビットの誤りを検出可能\n",
    "\n",
    "### 二次元パリティ\n",
    "\n",
    "- 二次元的にパリティビットを持たせる方式\n",
    "- パリティビットが化ける場合もある\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
